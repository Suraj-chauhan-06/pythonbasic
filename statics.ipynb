{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UYtBYVpwD1of"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üìò Theory Questions\n",
        "1. What is hypothesis testing in statistics?\n",
        "\n",
        "Hypothesis testing is a statistical method used to make decisions or inferences about population parameters based on sample data.\n",
        "\n",
        "2. What is the null hypothesis, and how does it differ from the alternative hypothesis?\n",
        "\n",
        "The null hypothesis (H‚ÇÄ) assumes no effect or difference; the alternative hypothesis (H‚ÇÅ) contradicts H‚ÇÄ and suggests an effect or difference exists.\n",
        "\n",
        "3. What is the significance level in hypothesis testing, and why is it important?\n",
        "\n",
        "It‚Äôs the probability of rejecting a true null hypothesis (Type I error), typically set at 0.05. It defines the threshold for statistical significance.\n",
        "\n",
        "4. What does a P-value represent in hypothesis testing?\n",
        "\n",
        "It is the probability of observing the test results under the null hypothesis.\n",
        "\n",
        "5. How do you interpret the P-value in hypothesis testing?\n",
        "\n",
        "If P-value < Œ±, reject H‚ÇÄ; otherwise, fail to reject H‚ÇÄ.\n",
        "\n",
        "6. What are Type 1 and Type 2 errors in hypothesis testing?\n",
        "\n",
        "Type I error: Rejecting H‚ÇÄ when it is true.\n",
        "\n",
        "Type II error: Failing to reject H‚ÇÄ when it is false.\n",
        "\n",
        "7. What is the difference between a one-tailed and a two-tailed test?\n",
        "\n",
        "One-tailed: Tests for effect in one direction.\n",
        "\n",
        "Two-tailed: Tests for effects in both directions.\n",
        "\n",
        "8. What is the Z-test, and when is it used?\n",
        "\n",
        "Used when population variance is known and sample size is large (n > 30), to compare means or proportions.\n",
        "\n",
        "9. How do you calculate the Z-score and what does it represent?\n",
        "ùëç\n",
        "=\n",
        "ùë•\n",
        "Àâ\n",
        "‚àí\n",
        "ùúá\n",
        "ùúé\n",
        "/\n",
        "ùëõ\n",
        "Z=\n",
        "œÉ/\n",
        "n\n",
        "‚Äã\n",
        "\n",
        "x\n",
        "Àâ\n",
        " ‚àíŒº\n",
        "‚Äã\n",
        "\n",
        "Represents how many standard deviations the sample mean is from the population mean.\n",
        "\n",
        "10. What is the T-distribution, and when should it be used?\n",
        "\n",
        "Used when the sample size is small and population standard deviation is unknown.\n",
        "\n",
        "11. Difference between a Z-test and a T-test?\n",
        "\n",
        "Z-test uses known population variance; T-test uses sample variance.\n",
        "\n",
        "12. What is the T-test, and how is it used?\n",
        "\n",
        "A T-test assesses whether the means of two groups are statistically different.\n",
        "\n",
        "Z-test vs T-test in hypothesis testing:\n",
        "Both compare means, but Z-test is for large samples with known variance; T-test is for smaller samples with unknown variance.\n",
        "\n",
        "14. What is a confidence interval?\n",
        "\n",
        "A range of values derived from sample data that is likely to contain the population parameter.\n",
        "\n",
        "15. What is the margin of error?\n",
        "\n",
        "The range added/subtracted to a point estimate in a confidence interval; increases with confidence level and decreases with larger samples.\n",
        "\n",
        "16. Bayes‚Äô Theorem in statistics:\n",
        "\n",
        "Updates the probability of a hypothesis based on new evidence.\n",
        "ùëÉ\n",
        "(\n",
        "ùêª\n",
        "‚à£\n",
        "ùê∏\n",
        ")\n",
        "=\n",
        "ùëÉ\n",
        "(\n",
        "ùê∏\n",
        "‚à£\n",
        "ùêª\n",
        ")\n",
        "ùëÉ\n",
        "(\n",
        "ùêª\n",
        ")\n",
        "ùëÉ\n",
        "(\n",
        "ùê∏\n",
        ")\n",
        "P(H‚à£E)=\n",
        "P(E)\n",
        "P(E‚à£H)P(H)\n",
        "‚Äã\n",
        "\n",
        "\n",
        "17. What is the Chi-square distribution?\n",
        "\n",
        "A distribution used for categorical data to test goodness-of-fit or independence.\n",
        "\n",
        "18. Chi-square goodness-of-fit test:\n",
        "\n",
        "Compares observed vs expected frequencies to test distribution fit.\n",
        "\n",
        "19. What is the F-distribution?\n",
        "\n",
        "A right-skewed distribution used in ANOVA and variance comparison.\n",
        "\n",
        "20. What is ANOVA and its assumptions?\n",
        "\n",
        "ANOVA tests mean differences across groups. Assumptions: independence, normality, and equal variance.\n",
        "\n",
        "21. Types of ANOVA tests:\n",
        "\n",
        "One-way ANOVA\n",
        "\n",
        "Two-way ANOVA\n",
        "\n",
        "Repeated measures ANOVA\n",
        "\n",
        "22. What is the F-test in hypothesis testing?\n",
        "\n",
        "Compares variances; used in ANOVA.\n",
        "\n"
      ],
      "metadata": {
        "id": "e1uq4bytD6tP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "1.'''Write a Python program to perform a Z-test for comparing a sample mean to a known population mean and\n",
        "interpret the results@'''\n",
        "\n",
        "import scipy.stats as stats\n",
        "import numpy as np\n",
        "\n",
        "def z_test(sample_data, population_mean, population_std, alpha=0.05):\n",
        "    # Convert sample data to a NumPy array\n",
        "    sample = np.array(sample_data)\n",
        "    sample_mean = np.mean(sample)\n",
        "    sample_size = len(sample)\n",
        "\n",
        "    # Calculate the standard error\n",
        "    standard_error = population_std / np.sqrt(sample_size)\n",
        "\n",
        "    # Calculate the Z-score\n",
        "    z_score = (sample_mean - population_mean) / standard_error\n",
        "\n",
        "    # Calculate the p-value (two-tailed test)\n",
        "    p_value = 2 * (1 - stats.norm.cdf(abs(z_score)))\n",
        "\n",
        "    # Output\n",
        "    print(\"Sample Mean:\", sample_mean)\n",
        "    print(\"Z-score:\", z_score)\n",
        "    print(\"P-value:\", p_value)\n",
        "\n",
        "    # Interpretation\n",
        "    if p_value < alpha:\n",
        "        print(f\"Reject the null hypothesis at alpha = {alpha}\")\n",
        "        print(\"There is a statistically significant difference between the sample mean and the population mean.\")\n",
        "    else:\n",
        "        print(f\"Fail to reject the null hypothesis at alpha = {alpha}\")\n",
        "        print(\"There is no statistically significant difference between the sample mean and the population mean.\")\n",
        "\n",
        "# Example usage\n",
        "sample_data = [50, 52, 47, 49, 53, 48, 50, 51, 49, 50]  # Example sample data\n",
        "population_mean = 48                                   # Known population mean\n",
        "population_std = 2.5                                    # Known population standard deviation\n",
        "\n",
        "z_test(sample_data, population_mean, population_std)\n"
      ],
      "metadata": {
        "id": "4MVIFjEvGE2i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "2.''' Simulate random data to perform hypothesis testing and calculate the corresponding P-value using Python'''\n",
        "\n",
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "\n",
        "def simulate_z_test(sample_size=30, population_mean=100, population_std=15, sample_mean_shift=0, alpha=0.05):\n",
        "    # Simulate random sample from a normal distribution\n",
        "    np.random.seed(42)  # For reproducibility\n",
        "    sample = np.random.normal(loc=population_mean + sample_mean_shift, scale=population_std, size=sample_size)\n",
        "\n",
        "    # Sample statistics\n",
        "    sample_mean = np.mean(sample)\n",
        "    standard_error = population_std / np.sqrt(sample_size)\n",
        "\n",
        "    # Z-test calculation\n",
        "    z_score = (sample_mean - population_mean) / standard_error\n",
        "    p_value = 2 * (1 - stats.norm.cdf(abs(z_score)))  # Two-tailed test\n",
        "\n",
        "    # Results\n",
        "    print(\"Sample Mean:\", round(sample_mean, 2))\n",
        "    print(\"Population Mean:\", population_mean)\n",
        "    print(\"Z-score:\", round(z_score, 4))\n",
        "    print(\"P-value:\", round(p_value, 4))\n",
        "\n",
        "    # Interpretation\n",
        "    if p_value < alpha:\n",
        "        print(\"Reject the null hypothesis.\")\n",
        "        print(\"The sample mean is significantly different from the population mean.\")\n",
        "    else:\n",
        "        print(\"Fail to reject the null hypothesis.\")\n",
        "        print(\"No significant difference between the sample and population mean.\")\n",
        "\n",
        "# Example run\n",
        "simulate_z_test(sample_size=50, population_mean=100, population_std=15, sample_mean_shift=5)\n"
      ],
      "metadata": {
        "id": "Kdg66TYPGsEP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "3.'''@ Implement a one-sample Z-test using Python to compare the sample mean with the population mean'''\n",
        "\n",
        "import numpy as np\n",
        "from scipy.stats import norm\n",
        "\n",
        "def one_sample_z_test(sample_data, population_mean, population_std, alpha=0.05):\n",
        "    \"\"\"\n",
        "    Perform a one-sample Z-test.\n",
        "\n",
        "    Parameters:\n",
        "    - sample_data (list or array): The sample observations.\n",
        "    - population_mean (float): The known population mean.\n",
        "    - population_std (float): The known population standard deviation.\n",
        "    - alpha (float): Significance level (default 0.05).\n",
        "\n",
        "    Returns:\n",
        "    - z_score (float)\n",
        "    - p_value (float)\n",
        "    - test_result (str)\n",
        "    \"\"\"\n",
        "    sample_data = np.array(sample_data)\n",
        "    sample_mean = np.mean(sample_data)\n",
        "    sample_size = len(sample_data)\n",
        "\n",
        "    # Standard error\n",
        "    standard_error = population_std / np.sqrt(sample_size)\n",
        "\n",
        "    # Z-score calculation\n",
        "    z_score = (sample_mean - population_mean) / standard_error\n",
        "\n",
        "    # Two-tailed p-value\n",
        "    p_value = 2 * (1 - norm.cdf(abs(z_score)))\n",
        "\n",
        "    # Interpretation\n",
        "    if p_value < alpha:\n",
        "        test_result = \"Reject the null hypothesis: sample mean is significantly different from the population mean.\"\n",
        "    else:\n",
        "        test_result = \"Fail to reject the null hypothesis: no significant difference between sample and population mean.\"\n",
        "\n",
        "    # Output\n",
        "    print(f\"Sample Mean: {sample_mean:.4f}\")\n",
        "    print(f\"Z-Score: {z_score:.4f}\")\n",
        "    print(f\"P-Value: {p_value:.4f}\")\n",
        "    print(\"Result:\", test_result)\n",
        "\n",
        "    return z_score, p_value, test_result\n",
        "\n",
        "# Example usage\n",
        "sample_data = [102, 100, 98, 101, 99, 97, 100, 103, 98, 100]\n",
        "population_mean = 100\n",
        "population_std = 2  # Known population standard deviation\n",
        "\n",
        "one_sample_z_test(sample_data, population_mean, population_std)\n"
      ],
      "metadata": {
        "id": "P7gDkyQeG7aj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "4.'''@ Perform a two-tailed Z-test using Python and visualize the decision region on a plot@'''\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import norm\n",
        "\n",
        "def two_tailed_z_test_with_plot(sample_data, population_mean, population_std, alpha=0.05):\n",
        "    # Step 1: Calculate sample statistics\n",
        "    sample_data = np.array(sample_data)\n",
        "    sample_mean = np.mean(sample_data)\n",
        "    n = len(sample_data)\n",
        "    standard_error = population_std / np.sqrt(n)\n",
        "\n",
        "    # Step 2: Calculate Z-score and p-value\n",
        "    z_score = (sample_mean - population_mean) / standard_error\n",
        "    p_value = 2 * (1 - norm.cdf(abs(z_score)))  # Two-tailed test\n",
        "\n",
        "    # Step 3: Print results\n",
        "    print(f\"Sample Mean: {sample_mean:.2f}\")\n",
        "    print(f\"Z-score: {z_score:.4f}\")\n",
        "    print(f\"P-value: {p_value:.4f}\")\n",
        "\n",
        "    if p_value < alpha:\n",
        "        print(\"Reject the null hypothesis.\")\n",
        "    else:\n",
        "        print(\"Fail to reject the null hypothesis.\")\n",
        "\n",
        "    # Step 4: Plot the decision region\n",
        "    x = np.linspace(-4, 4, 1000)\n",
        "    y = norm.pdf(x, 0, 1)\n",
        "\n",
        "    z_critical = norm.ppf(1 - alpha / 2)\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(x, y, label='Standard Normal Distribution', color='blue')\n",
        "    plt.fill_between(x, y, where=(x < -z_critical) | (x > z_critical), color='red', alpha=0.3, label='Rejection Region')\n",
        "    plt.axvline(z_score, color='black', linestyle='--', label=f'Z-score = {z_score:.2f}')\n",
        "    plt.axvline(-z_critical, color='red', linestyle='--', label=f'Critical Z = ¬±{z_critical:.2f}')\n",
        "    plt.axvline(z_critical, color='red', linestyle='--')\n",
        "    plt.title('Two-Tailed Z-Test')\n",
        "    plt.xlabel('Z')\n",
        "    plt.ylabel('Probability Density')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "# Example usage\n",
        "sample_data = [102, 100, 98, 101, 99, 97, 100, 103, 98, 100]\n",
        "population_mean = 100\n",
        "population_std = 2  # Known population standard deviation\n",
        "\n",
        "two_tailed_z_test_with_plot(sample_data, population_mean, population_std)\n"
      ],
      "metadata": {
        "id": "bCENzxl5HKxA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "5.'''Create a Python function that calculates and visualizes Type 1 and Type 2 errors during hypothesis testing'''\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import norm\n",
        "\n",
        "def visualize_type1_type2_errors(mu0=100, mu1=105, sigma=10, n=30, alpha=0.05):\n",
        "    \"\"\"\n",
        "    Visualizes Type I and Type II errors for a one-sample Z-test.\n",
        "\n",
        "    Parameters:\n",
        "    - mu0: Mean under null hypothesis (H0)\n",
        "    - mu1: Mean under alternative hypothesis (H1)\n",
        "    - sigma: Population standard deviation\n",
        "    - n: Sample size\n",
        "    - alpha: Significance level (Type I error rate)\n",
        "    \"\"\"\n",
        "    # Standard error of the mean\n",
        "    se = sigma / np.sqrt(n)\n",
        "\n",
        "    # Critical value for right-tailed test\n",
        "    z_crit = norm.ppf(1 - alpha)\n",
        "    x_crit = mu0 + z_crit * se  # Critical sample mean under H0\n",
        "\n",
        "    # Beta (Type II error): P(fail to reject H0 when H1 is true)\n",
        "    z_beta = (x_crit - mu1) / se\n",
        "    beta = norm.cdf(z_beta)\n",
        "\n",
        "    # Plot range\n",
        "    x = np.linspace(mu0 - 4 * se, mu1 + 4 * se, 1000)\n",
        "    h0_pdf = norm.pdf(x, mu0, se)\n",
        "    h1_pdf = norm.pdf(x, mu1, se)\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(x, h0_pdf, label='H‚ÇÄ Distribution (Œº‚ÇÄ)', color='blue')\n",
        "    plt.plot(x, h1_pdf, label='H‚ÇÅ Distribution (Œº‚ÇÅ)', color='green')\n",
        "\n",
        "    # Shade Type I error region (alpha)\n",
        "    x_alpha = np.linspace(x_crit, mu0 + 4 * se, 1000)\n",
        "    plt.fill_between(x_alpha, norm.pdf(x_alpha, mu0, se), color='red', alpha=0.3, label='Type I Error (Œ±)')\n",
        "\n",
        "    # Shade Type II error region (beta)\n",
        "    x_beta = np.linspace(mu0 - 4 * se, x_crit, 1000)\n",
        "    plt.fill_between(x_beta, norm.pdf(x_beta, mu1, se), color='orange', alpha=0.4, label='Type II Error (Œ≤)')\n",
        "\n",
        "    # Mark critical value\n",
        "    plt.axvline(x_crit, color='black', linestyle='--', label=f'Critical Value = {x_crit:.2f}')\n",
        "\n",
        "    # Labels and legend\n",
        "    plt.title('Visualization of Type I and Type II Errors')\n",
        "    plt.xlabel('Sample Mean')\n",
        "    plt.ylabel('Probability Density')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    print(f\"Critical value (sample mean cutoff): {x_crit:.2f}\")\n",
        "    print(f\"Type II Error (Œ≤): {beta:.4f}\")\n",
        "    print(f\"Power of the test (1 - Œ≤): {1 - beta:.4f}\")\n"
      ],
      "metadata": {
        "id": "rgNVqNbiHd7b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "6'''Write a Python program to perform an independent T-test and interpret the results'''\n",
        "\n",
        "import numpy as np\n",
        "from scipy import stats\n",
        "\n",
        "def independent_t_test(sample1, sample2, alpha=0.05, equal_var=False):\n",
        "    \"\"\"\n",
        "    Perform an independent two-sample t-test and interpret the results.\n",
        "\n",
        "    Parameters:\n",
        "    - sample1: List or array of values for group 1\n",
        "    - sample2: List or array of values for group 2\n",
        "    - alpha: Significance level (default = 0.05)\n",
        "    - equal_var: Assume equal population variances (default = False)\n",
        "\n",
        "    Returns:\n",
        "    - t_stat: T-statistic value\n",
        "    - p_value: P-value from the test\n",
        "    - conclusion: Interpretation of the hypothesis test\n",
        "    \"\"\"\n",
        "\n",
        "    # Convert to NumPy arrays\n",
        "    sample1 = np.array(sample1)\n",
        "    sample2 = np.array(sample2)\n",
        "\n",
        "    # Perform the t-test\n",
        "    t_stat, p_value = stats.ttest_ind(sample1, sample2, equal_var=equal_var)\n",
        "\n",
        "    # Output results\n",
        "    print(f\"Sample 1 Mean: {np.mean(sample1):.2f}\")\n",
        "    print(f\"Sample 2 Mean: {np.mean(sample2):.2f}\")\n",
        "    print(f\"T-statistic: {t_stat:.4f}\")\n",
        "    print(f\"P-value: {p_value:.4f}\")\n",
        "\n",
        "    # Interpretation\n",
        "    if p_value < alpha:\n",
        "        conclusion = \"Reject the null hypothesis: There is a significant difference between the two groups.\"\n",
        "    else:\n",
        "        conclusion = \"Fail to reject the null hypothesis: No significant difference between the two groups.\"\n",
        "\n",
        "    print(\"Conclusion:\", conclusion)\n",
        "\n",
        "    return t_stat, p_value, conclusion\n",
        "\n",
        "# Example usage\n",
        "group1 = [22, 25, 19, 23, 20, 18, 24]\n",
        "group2 = [28, 30, 27, 29, 31, 26, 32]\n",
        "\n",
        "independent_t_test(group1, group2)\n"
      ],
      "metadata": {
        "id": "qTiM-Hk8H3ZX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "7.'''Perform a paired sample T-test using Python and visualize the comparison results'''\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import ttest_rel\n",
        "\n",
        "def paired_t_test_with_plot(before, after, alpha=0.05):\n",
        "    \"\"\"\n",
        "    Performs a paired sample t-test and visualizes the results.\n",
        "\n",
        "    Parameters:\n",
        "    - before: List or array of 'before' measurements.\n",
        "    - after: List or array of 'after' measurements.\n",
        "    - alpha: Significance level (default = 0.05).\n",
        "    \"\"\"\n",
        "    before = np.array(before)\n",
        "    after = np.array(after)\n",
        "    differences = after - before\n",
        "\n",
        "    # Paired t-test\n",
        "    t_stat, p_value = ttest_rel(before, after)\n",
        "\n",
        "    # Output results\n",
        "    print(f\"Mean (Before): {np.mean(before):.2f}\")\n",
        "    print(f\"Mean (After): {np.mean(after):.2f}\")\n",
        "    print(f\"Mean Difference: {np.mean(differences):.2f}\")\n",
        "    print(f\"T-statistic: {t_stat:.4f}\")\n",
        "    print(f\"P-value: {p_value:.4f}\")\n",
        "\n",
        "    if p_value < alpha:\n",
        "        print(\"Reject the null hypothesis: There is a significant difference between 'before' and 'after'.\")\n",
        "    else:\n",
        "        print(\"Fail to reject the null hypothesis: No significant difference found.\")\n",
        "\n",
        "    # Visualization: Before vs After\n",
        "    plt.figure(figsize=(12, 5))\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(before, label='Before', marker='o')\n",
        "    plt.plot(after, label='After', marker='o')\n",
        "    plt.title('Before vs After')\n",
        "    plt.xlabel('Subject Index')\n",
        "    plt.ylabel('Measurement')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "\n",
        "    # Visualization: Differences\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.hist(differences, bins=10, color='skyblue', edgecolor='black')\n",
        "    plt.axvline(np.mean(differences), color='red', linestyle='--', label='Mean Difference')\n",
        "    plt.title('Distribution of Paired Differences (After - Before)')\n",
        "    plt.xlabel('Difference')\n",
        "    plt.ylabel('Frequency')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Example usage\n",
        "before_scores = [72, 75, 78, 71, 69, 74, 70, 68, 73, 76]\n",
        "after_scores  = [75, 78, 80, 74, 72, 76, 73, 70, 76, 79]\n",
        "\n",
        "paired_t_test_with_plot(before_scores, after_scores)\n"
      ],
      "metadata": {
        "id": "DOH9EhSFIKGz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "8.'''Simulate data and perform both Z-test and T-test, then compare the results using Python'''\n",
        "\n",
        "import numpy as np\n",
        "from scipy import stats\n",
        "\n",
        "# Simulate data\n",
        "np.random.seed(42)\n",
        "sample_size = 40\n",
        "population_mean = 50\n",
        "population_std = 10  # Known population std dev for Z-test\n",
        "\n",
        "# Generate a sample with a true mean around 52 (slightly different from 50)\n",
        "sample = np.random.normal(loc=52, scale=population_std, size=sample_size)\n",
        "\n",
        "# 1. Z-test (one sample)\n",
        "# Z = (sample_mean - population_mean) / (population_std / sqrt(n))\n",
        "sample_mean = np.mean(sample)\n",
        "z_stat = (sample_mean - population_mean) / (population_std / np.sqrt(sample_size))\n",
        "# two-tailed p-value for Z-test\n",
        "z_p_value = 2 * (1 - stats.norm.cdf(abs(z_stat)))\n",
        "\n",
        "# 2. T-test (one sample)\n",
        "# Use scipy ttest_1samp, population mean = 50\n",
        "t_stat, t_p_value = stats.ttest_1samp(sample, population_mean)\n",
        "\n",
        "# Print results\n",
        "print(f\"Sample Mean: {sample_mean:.4f}\")\n",
        "print(f\"Z-test statistic: {z_stat:.4f}, p-value: {z_p_value:.4f}\")\n",
        "print(f\"T-test statistic: {t_stat:.4f}, p-value: {t_p_value:.4f}\")\n"
      ],
      "metadata": {
        "id": "5ONAFu61Ie2D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "9'''Write a Python function to calculate the confidence interval for a sample mean and explain its significance'''\n",
        "\n",
        "import numpy as np\n",
        "from scipy import stats\n",
        "\n",
        "def confidence_interval(data, confidence=0.95):\n",
        "    \"\"\"\n",
        "    Calculate the confidence interval for the mean of a sample.\n",
        "\n",
        "    Parameters:\n",
        "    - data: list or numpy array of sample observations\n",
        "    - confidence: confidence level (default 0.95 for 95% confidence)\n",
        "\n",
        "    Returns:\n",
        "    - (lower_bound, upper_bound): tuple with confidence interval limits\n",
        "    \"\"\"\n",
        "    n = len(data)\n",
        "    mean = np.mean(data)\n",
        "    sem = stats.sem(data)  # standard error of the mean\n",
        "\n",
        "    # t critical value for two-tailed test\n",
        "    t_crit = stats.t.ppf((1 + confidence) / 2, df=n-1)\n",
        "\n",
        "    margin_of_error = t_crit * sem\n",
        "    lower_bound = mean - margin_of_error\n",
        "    upper_bound = mean + margin_of_error\n",
        "\n",
        "    return lower_bound, upper_bound\n"
      ],
      "metadata": {
        "id": "wiZRWGR0I0rp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "10'''Write a Python program to calculate the margin of error for a given confidence level using sample data'''\n",
        "\n",
        "import numpy as np\n",
        "from scipy import stats\n",
        "\n",
        "def margin_of_error(data, confidence=0.95):\n",
        "    \"\"\"\n",
        "    Calculate the margin of error for the sample mean at a specified confidence level.\n",
        "\n",
        "    Parameters:\n",
        "    - data: list or numpy array of sample observations\n",
        "    - confidence: confidence level (default is 0.95 for 95%)\n",
        "\n",
        "    Returns:\n",
        "    - margin_of_error: the margin of error for the mean\n",
        "    \"\"\"\n",
        "    n = len(data)\n",
        "    sem = stats.sem(data)  # standard error of the mean\n",
        "\n",
        "    # Get t critical value for two-tailed test\n",
        "    t_crit = stats.t.ppf((1 + confidence) / 2, df=n-1)\n",
        "\n",
        "    return t_crit * sem\n",
        "\n",
        "# Example usage:\n",
        "if __name__ == \"__main__\":\n",
        "    # Sample data\n",
        "    sample_data = [12, 15, 14, 10, 13, 15, 16, 14, 13, 12]\n",
        "    conf_level = 0.95  # 95% confidence\n",
        "\n",
        "    me = margin_of_error(sample_data, conf_level)\n",
        "    print(f\"Margin of Error at {conf_level*100}% confidence: {me:.4f}\")\n"
      ],
      "metadata": {
        "id": "TpR4uB2zI9L4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "11'''Implement a Bayesian inference method using Bayes' Theorem in Python and explain the process'''\n",
        "\n",
        "def bayes_theorem(P_disease, P_pos_given_disease, P_pos_given_no_disease):\n",
        "    \"\"\"\n",
        "    Calculate posterior probability P(Disease | Positive) using Bayes' Theorem.\n",
        "\n",
        "    Parameters:\n",
        "    - P_disease: Prior probability of disease\n",
        "    - P_pos_given_disease: Probability of positive test given disease (True Positive rate)\n",
        "    - P_pos_given_no_disease: Probability of positive test given no disease (False Positive rate)\n",
        "\n",
        "    Returns:\n",
        "    - Posterior probability P(Disease | Positive)\n",
        "    \"\"\"\n",
        "    P_no_disease = 1 - P_disease\n",
        "\n",
        "    # Total probability of positive test\n",
        "    P_positive = (P_pos_given_disease * P_disease) + (P_pos_given_no_disease * P_no_disease)\n",
        "\n",
        "    # Bayes theorem\n",
        "    P_disease_given_positive = (P_pos_given_disease * P_disease) / P_positive\n",
        "\n",
        "    return P_disease_given_positive\n",
        "\n",
        "\n",
        "# Parameters:\n",
        "P_disease = 0.005  # 0.5% prevalence\n",
        "P_pos_given_disease = 0.99  # True positive rate\n",
        "P_pos_given_no_disease = 0.01  # False positive rate (1 - specificity)\n",
        "\n",
        "posterior_prob = bayes_theorem(P_disease, P_pos_given_disease, P_pos_given_no_disease)\n",
        "\n",
        "print(f\"Probability of having the disease given a positive test: {posterior_prob:.4f} ({posterior_prob*100:.2f}%)\")\n"
      ],
      "metadata": {
        "id": "EU-F9I94JFHj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "12''' Perform a Chi-square test for independence between two categorical variables in Python'''\n",
        "\n",
        "import numpy as np\n",
        "from scipy.stats import chi2_contingency\n",
        "\n",
        "# Example contingency table\n",
        "# Rows: Gender (Male, Female)\n",
        "# Columns: Preference (Product A, Product B)\n",
        "# Values: Counts of observations\n",
        "contingency_table = np.array([[30, 10],   # Male\n",
        "                              [20, 40]])  # Female\n",
        "\n",
        "# Perform Chi-square test\n",
        "chi2, p, dof, expected = chi2_contingency(contingency_table)\n",
        "\n",
        "print(f\"Chi-square statistic: {chi2:.4f}\")\n",
        "print(f\"Degrees of freedom: {dof}\")\n",
        "print(f\"P-value: {p:.4f}\")\n",
        "print(\"Expected frequencies if independent:\")\n",
        "print(expected)\n",
        "\n",
        "# Interpretation\n",
        "alpha = 0.05\n",
        "if p < alpha:\n",
        "    print(\"Reject null hypothesis: Variables are dependent (not independent).\")\n",
        "else:\n",
        "    print(\"Fail to reject null hypothesis: No evidence variables are dependent.\")\n"
      ],
      "metadata": {
        "id": "47MZiXnBJQfZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "13''' Write a Python program to calculate the expected frequencies for a Chi-square test based on observed\n",
        "data'''\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "def expected_frequencies(observed):\n",
        "    \"\"\"\n",
        "    Calculate expected frequencies for a contingency table.\n",
        "\n",
        "    Parameters:\n",
        "    - observed: 2D numpy array of observed frequencies\n",
        "\n",
        "    Returns:\n",
        "    - expected: 2D numpy array of expected frequencies\n",
        "    \"\"\"\n",
        "    row_totals = observed.sum(axis=1, keepdims=True)\n",
        "    col_totals = observed.sum(axis=0, keepdims=True)\n",
        "    grand_total = observed.sum()\n",
        "\n",
        "    expected = row_totals @ col_totals / grand_total\n",
        "    return expected\n",
        "\n",
        "# Example observed data\n",
        "observed_data = np.array([[30, 10],\n",
        "                          [20, 40]])\n",
        "\n",
        "expected = expected_frequencies(observed_data)\n",
        "print(\"Observed frequencies:\")\n",
        "print(observed_data)\n",
        "print(\"\\nExpected frequencies:\")\n",
        "print(expected)\n"
      ],
      "metadata": {
        "id": "a1nsunKGJYzQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "14''' Perform a goodness-of-fit test using Python to compare the observed data to an expected distribution'''\n",
        "\n",
        "from scipy.stats import chisquare\n",
        "import numpy as np\n",
        "\n",
        "# Observed counts (e.g., counts of categories)\n",
        "observed = np.array([50, 30, 20])\n",
        "\n",
        "# Expected proportions or counts\n",
        "# If proportions, multiply by total to get expected counts\n",
        "expected_proportions = np.array([0.4, 0.4, 0.2])\n",
        "expected = expected_proportions * observed.sum()\n",
        "\n",
        "# Perform Chi-square goodness-of-fit test\n",
        "chi2_stat, p_value = chisquare(f_obs=observed, f_exp=expected)\n",
        "\n",
        "print(f\"Chi-square statistic: {chi2_stat:.4f}\")\n",
        "print(f\"P-value: {p_value:.4f}\")\n",
        "\n",
        "alpha = 0.05\n",
        "if p_value < alpha:\n",
        "    print(\"Reject null hypothesis: Observed data does NOT fit the expected distribution.\")\n",
        "else:\n",
        "    print(\"Fail to reject null hypothesis: Observed data fits the expected distribution.\")\n",
        "\n"
      ],
      "metadata": {
        "id": "52NH4a86Jf1J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "15'''Create a Python script to simulate and visualize the Chi-square distribution and discuss its characteristics'''\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import chi2\n",
        "\n",
        "# Parameters\n",
        "df = 4  # degrees of freedom\n",
        "sample_size = 10000\n",
        "\n",
        "# Simulate data from Chi-square distribution\n",
        "data = np.random.chisquare(df, size=sample_size)\n",
        "\n",
        "# Plot histogram of simulated data\n",
        "plt.hist(data, bins=50, density=True, alpha=0.6, color='skyblue', label='Simulated data')\n",
        "\n",
        "# Plot theoretical Chi-square PDF\n",
        "x = np.linspace(0, np.max(data), 1000)\n",
        "pdf = chi2.pdf(x, df)\n",
        "plt.plot(x, pdf, 'r-', lw=2, label=f'Chi-square PDF (df={df})')\n",
        "\n",
        "# Labels and title\n",
        "plt.title('Chi-square Distribution Simulation')\n",
        "plt.xlabel('Value')\n",
        "plt.ylabel('Density')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "7pi2jE92JpUK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "16'''Implement an F-test using Python to compare the variances of two random samples'''\n",
        "\n",
        "import numpy as np\n",
        "from scipy.stats import f\n",
        "\n",
        "def f_test(sample1, sample2, alpha=0.05):\n",
        "    \"\"\"\n",
        "    Perform an F-test to compare variances of two samples.\n",
        "\n",
        "    Parameters:\n",
        "    - sample1, sample2: arrays or lists of sample data\n",
        "    - alpha: significance level (default 0.05)\n",
        "\n",
        "    Returns:\n",
        "    - F statistic, p-value, conclusion string\n",
        "    \"\"\"\n",
        "    var1 = np.var(sample1, ddof=1)\n",
        "    var2 = np.var(sample2, ddof=1)\n",
        "\n",
        "    # Arrange so that var1 >= var2\n",
        "    if var1 < var2:\n",
        "        var1, var2 = var2, var1\n",
        "        dfn, dfd = len(sample2) - 1, len(sample1) - 1\n",
        "    else:\n",
        "        dfn, dfd = len(sample1) - 1, len(sample2) - 1\n",
        "\n",
        "    F = var1 / var2\n",
        "\n",
        "    # Two-tailed p-value calculation\n",
        "    p_value = 2 * min(f.cdf(F, dfn, dfd), 1 - f.cdf(F, dfn, dfd))\n",
        "\n",
        "    conclusion = \"Fail to reject null hypothesis: variances are equal.\"\n",
        "    if p_value < alpha:\n",
        "        conclusion = \"Reject null hypothesis: variances are different.\"\n",
        "\n",
        "    return F, p_value, conclusion\n",
        "\n",
        "# Example usage:\n",
        "np.random.seed(42)\n",
        "sample1 = np.random.normal(0, 5, 30)  # std dev = 5\n",
        "sample2 = np.random.normal(0, 7, 35)  # std dev = 7\n",
        "\n",
        "F_stat, p_val, result = f_test(sample1, sample2)\n",
        "print(f\"F-statistic: {F_stat:.4f}\")\n",
        "print(f\"P-value: {p_val:.4f}\")\n",
        "print(result)\n"
      ],
      "metadata": {
        "id": "1lZyhhdJJyl6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "17'''Write a Python program to perform an ANOVA test to compare means between multiple groups and\n",
        "interpret the results'''\n",
        "\n",
        "import numpy as np\n",
        "from scipy.stats import f_oneway\n",
        "\n",
        "# Sample data: Suppose we have three groups with observed values\n",
        "group1 = [23, 20, 22, 21, 24]\n",
        "group2 = [30, 29, 31, 28, 32]\n",
        "group3 = [22, 23, 21, 20, 19]\n",
        "\n",
        "# Perform one-way ANOVA\n",
        "F_statistic, p_value = f_oneway(group1, group2, group3)\n",
        "\n",
        "print(f\"ANOVA F-statistic: {F_statistic:.4f}\")\n",
        "print(f\"P-value: {p_value:.4f}\")\n",
        "\n",
        "# Interpret results\n",
        "alpha = 0.05\n",
        "if p_value < alpha:\n",
        "    print(\"Reject the null hypothesis: There is a significant difference between group means.\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis: No significant difference between group means.\")\n"
      ],
      "metadata": {
        "id": "SfAo99xoJ7eU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "18''' Perform a one-way ANOVA test using Python to compare the means of different groups and plot the results'''\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import f_oneway\n",
        "\n",
        "# Sample data for three groups\n",
        "group1 = [23, 20, 22, 21, 24]\n",
        "group2 = [30, 29, 31, 28, 32]\n",
        "group3 = [22, 23, 21, 20, 19]\n",
        "\n",
        "# Perform one-way ANOVA\n",
        "F_statistic, p_value = f_oneway(group1, group2, group3)\n",
        "\n",
        "print(f\"ANOVA F-statistic: {F_statistic:.4f}\")\n",
        "print(f\"P-value: {p_value:.4f}\")\n",
        "\n",
        "alpha = 0.05\n",
        "if p_value < alpha:\n",
        "    print(\"Reject null hypothesis: At least one group mean is different.\")\n",
        "else:\n",
        "    print(\"Fail to reject null hypothesis: No significant difference between means.\")\n",
        "\n",
        "# Plot boxplots of the groups\n",
        "plt.boxplot([group1, group2, group3], labels=['Group 1', 'Group 2', 'Group 3'])\n",
        "plt.title('Group Comparison using Boxplots')\n",
        "plt.ylabel('Values')\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "NwqR7MTWKB3x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "19'''Write a Python function to check the assumptions (normality, independence, and equal variance) for ANOVA'''\n",
        "\n",
        "import numpy as np\n",
        "from scipy.stats import shapiro, levene\n",
        "\n",
        "def check_anova_assumptions(*groups, alpha=0.05):\n",
        "    \"\"\"\n",
        "    Check ANOVA assumptions:\n",
        "    - Normality (Shapiro-Wilk test) for each group\n",
        "    - Homogeneity of variances (Levene's test)\n",
        "    - Independence (not testable here, just a reminder)\n",
        "\n",
        "    Parameters:\n",
        "    - groups: lists or arrays of group data\n",
        "    - alpha: significance level (default 0.05)\n",
        "\n",
        "    Returns:\n",
        "    - dict with results and interpretations\n",
        "    \"\"\"\n",
        "    results = {}\n",
        "\n",
        "    # Normality test per group\n",
        "    normality = []\n",
        "    for i, group in enumerate(groups, start=1):\n",
        "        stat, p = shapiro(group)\n",
        "        normality.append((stat, p))\n",
        "        print(f\"Group {i} Shapiro-Wilk p-value: {p:.4f} -> {'Normal' if p > alpha else 'Not normal'}\")\n",
        "\n",
        "    results['normality'] = normality\n",
        "\n",
        "    # Homogeneity of variances (Levene's test)\n",
        "    stat, p = levene(*groups)\n",
        "    results['levene'] = (stat, p)\n",
        "    print(f\"Levene's test p-value: {p:.4f} -> {'Equal variances' if p > alpha else 'Unequal variances'}\")\n",
        "\n",
        "    # Independence reminder\n",
        "    print(\"Independence assumption: Must be ensured by study design (random sampling, no related samples).\")\n",
        "\n",
        "    return results\n",
        "\n",
        "# Example usage:\n",
        "group1 = [23, 20, 22, 21, 24]\n",
        "group2 = [30, 29, 31, 28, 32]\n",
        "group3 = [22, 23, 21, 20, 19]\n",
        "\n",
        "check_anova_assumptions(group1, group2, group3)\n"
      ],
      "metadata": {
        "id": "ZjfgdwLBKJ7t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "20'''Perform a two-way ANOVA test using Python to study the interaction between two factors and visualize the  result'''\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.formula.api import ols\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Simulate example data\n",
        "np.random.seed(0)\n",
        "factor_A = ['Low', 'High']\n",
        "factor_B = ['Control', 'Treatment']\n",
        "\n",
        "# Create balanced dataset\n",
        "data = []\n",
        "for a in factor_A:\n",
        "    for b in factor_B:\n",
        "        # simulate 10 observations per group with some interaction effect\n",
        "        mean = 10 + (5 if a == 'High' else 0) + (3 if b == 'Treatment' else 0) + (2 if a == 'High' and b == 'Treatment' else 0)\n",
        "        observations = np.random.normal(loc=mean, scale=2, size=10)\n",
        "        for obs in observations:\n",
        "            data.append([a, b, obs])\n",
        "\n",
        "df = pd.DataFrame(data, columns=['FactorA', 'FactorB', 'Value'])\n",
        "\n",
        "# Fit two-way ANOVA model with interaction\n",
        "model = ols('Value ~ C(FactorA) * C(FactorB)', data=df).fit()\n",
        "anova_table = sm.stats.anova_lm(model, typ=2)\n",
        "print(anova_table)\n",
        "\n",
        "# Visualization: Interaction plot\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.pointplot(data=df, x='FactorA', y='Value', hue='FactorB', dodge=True, markers=['o', 's'], capsize=.1, errwidth=1)\n",
        "plt.title('Interaction Plot between FactorA and FactorB')\n",
        "plt.ylabel('Mean Value')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "qmyFAqp_KQum"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "21'''Write a Python program to visualize the F-distribution and discuss its use in hypothesis testing'''\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import f\n",
        "\n",
        "# Parameters for the F-distribution\n",
        "dfn = 5  # degrees of freedom numerator\n",
        "dfd = 10 # degrees of freedom denominator\n",
        "\n",
        "# Generate x values (F-distribution is only defined for x >= 0)\n",
        "x = np.linspace(0, 5, 500)\n",
        "\n",
        "# Compute the PDF of the F-distribution\n",
        "pdf = f.pdf(x, dfn, dfd)\n",
        "\n",
        "# Plot the F-distribution PDF\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(x, pdf, 'b-', lw=2, label=f'F-distribution\\n(dfnum={dfn}, dfden={dfd})')\n",
        "plt.title('F-distribution Probability Density Function')\n",
        "plt.xlabel('F value')\n",
        "plt.ylabel('Probability Density')\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "sG6i8DKcKbjA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "22''' Perform a one-way ANOVA test in Python and visualize the results with boxplots to compare group means'''\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy import stats\n",
        "\n",
        "# Generate sample data with 3 groups\n",
        "np.random.seed(42)\n",
        "group1 = np.random.normal(loc=50, scale=10, size=30)\n",
        "group2 = np.random.normal(loc=55, scale=10, size=30)\n",
        "group3 = np.random.normal(loc=60, scale=10, size=30)\n",
        "\n",
        "# Combine into a DataFrame for easier handling\n",
        "data = pd.DataFrame({\n",
        "    'values': np.concatenate([group1, group2, group3]),\n",
        "    'group': ['Group1'] * 30 + ['Group2'] * 30 + ['Group3'] * 30\n",
        "})\n",
        "\n",
        "# Perform one-way ANOVA\n",
        "f_stat, p_value = stats.f_oneway(group1, group2, group3)\n",
        "\n",
        "print(\"One-Way ANOVA Results:\")\n",
        "print(f\"F-statistic: {f_stat:.4f}\")\n",
        "print(f\"P-value: {p_value:.4f}\")\n",
        "\n",
        "# Interpret the p-value\n",
        "alpha = 0.05\n",
        "if p_value < alpha:\n",
        "    print(\"\\nThe p-value is less than 0.05. We reject the null hypothesis.\")\n",
        "    print(\"There are statistically significant differences between group means.\")\n",
        "else:\n",
        "    print(\"\\nThe p-value is greater than 0.05. We fail to reject the null hypothesis.\")\n",
        "    print(\"There are no statistically significant differences between group means.\")\n",
        "\n",
        "# Create boxplot to visualize the results\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.boxplot(x='group', y='values', data=data)\n",
        "plt.title('Comparison of Group Means with Boxplots', fontsize=14)\n",
        "plt.xlabel('Groups', fontsize=12)\n",
        "plt.ylabel('Values', fontsize=12)\n",
        "\n",
        "# Add annotation with ANOVA results\n",
        "plt.text(0.5, max(data['values']) * 1.05,\n",
        "         f'One-Way ANOVA: F = {f_stat:.2f}, p = {p_value:.4f}',\n",
        "         ha='center', va='center', fontsize=12)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "gRrFZLsYKrKk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "23'''Simulate random data from a normal distribution, then perform hypothesis testing to evaluate the means'''\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import stats\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "# Parameters for the normal distributions\n",
        "mean1, std1 = 50, 10\n",
        "mean2, std2 = 55, 10\n",
        "sample_size = 30\n",
        "\n",
        "# Generate two samples from normal distributions\n",
        "sample1 = np.random.normal(loc=mean1, scale=std1, size=sample_size)\n",
        "sample2 = np.random.normal(loc=mean2, scale=std2, size=sample_size)\n",
        "\n",
        "# Perform independent two-sample t-test (assuming equal variances)\n",
        "t_stat, p_value = stats.ttest_ind(sample1, sample2)\n",
        "\n",
        "print(\"Simulation Parameters:\")\n",
        "print(f\"Sample 1: Mean = {mean1}, Std = {std1}\")\n",
        "print(f\"Sample 2: Mean = {mean2}, Std = {std2}\")\n",
        "print(f\"Sample size for each group: {sample_size}\\n\")\n",
        "\n",
        "print(\"Hypothesis Test Results (Two-Sample t-test):\")\n",
        "print(f\"t-statistic: {t_stat:.4f}\")\n",
        "print(f\"p-value: {p_value:.4f}\")\n",
        "\n",
        "# Interpret the results\n",
        "alpha = 0.05\n",
        "print(\"\\nConclusion:\")\n",
        "if p_value < alpha:\n",
        "    print(f\"We reject the null hypothesis (p < {alpha}). There is significant evidence that the means are different.\")\n",
        "else:\n",
        "    print(f\"We fail to reject the null hypothesis (p ‚â• {alpha}). No significant difference in means detected.\")\n",
        "\n"
      ],
      "metadata": {
        "id": "5A6WWd9NN6VL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "24''' Perform a hypothesis test for population variance using a Chi-square distribution and interpret the results'''\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import stats\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "## 1. Generate sample data from a normal distribution\n",
        "true_mean = 50\n",
        "true_variance = 25  # œÉ¬≤ = 25 ‚Üí œÉ = 5\n",
        "sample_size = 30\n",
        "sample = np.random.normal(loc=true_mean, scale=np.sqrt(true_variance), size=sample_size)\n",
        "\n",
        "## 2. State the hypotheses\n",
        "# H‚ÇÄ: œÉ¬≤ = 25 (null hypothesis - population variance equals 25)\n",
        "# H‚ÇÅ: œÉ¬≤ ‚â† 25 (alternative hypothesis - two-tailed test)\n",
        "hypothesized_variance = 25\n",
        "alpha = 0.05  # significance level\n",
        "\n",
        "## 3. Calculate test statistic\n",
        "sample_variance = np.var(sample, ddof=1)  # sample variance with Bessel's correction (n-1)\n",
        "chi_square_stat = (sample_size - 1) * sample_variance / hypothesized_variance\n",
        "\n",
        "## 4. Calculate critical values and p-value\n",
        "df = sample_size - 1  # degrees of freedom\n",
        "lower_critical = stats.chi2.ppf(alpha/2, df)\n",
        "upper_critical = stats.chi2.ppf(1 - alpha/2, df)\n",
        "p_value = 2 * min(stats.chi2.cdf(chi_square_stat, df), 1 - stats.chi2.cdf(chi_square_stat, df))\n",
        "\n",
        "## 5. Print results\n",
        "print(f\"Sample variance: {sample_variance:.4f}\")\n",
        "print(f\"Chi-square test statistic: {chi_square_stat:.4f}\")\n",
        "print(f\"Critical values: ({lower_critical:.4f}, {upper_critical:.4f})\")\n",
        "print(f\"P-value: {p_value:.4f}\")\n",
        "\n",
        "## 6. Make decision\n",
        "if chi_square_stat < lower_critical or chi_square_stat > upper_critical:\n",
        "    print(f\"Reject H‚ÇÄ at Œ±={alpha} (test statistic outside critical region)\")\n",
        "else:\n",
        "    print(f\"Fail to reject H‚ÇÄ at Œ±={alpha}\")\n",
        "\n",
        "## 7. Interpretation\n",
        "print(\"\\nInterpretation:\")\n",
        "print(f\"We are testing whether the population variance differs from {hypothesized_variance}.\")\n",
        "if p_value < alpha:\n",
        "    print(f\"With p-value {p_value:.4f} < {alpha}, we have significant evidence to conclude\")\n",
        "    print(\"that the population variance is different from the hypothesized value.\")\n",
        "else:\n",
        "    print(f\"With p-value {p_value:.4f} ‚â• {alpha}, we don't have sufficient evidence\")\n",
        "    print(\"to conclude that the population variance differs from the hypothesized value.\")\n",
        "\n",
        "## 8. Visualization\n",
        "plt.figure(figsize=(10, 6))\n",
        "x = np.linspace(0, stats.chi2.ppf(0.999, df), 1000)\n",
        "y = stats.chi2.pdf(x, df)\n",
        "\n",
        "plt.plot(x, y, label=f'Chi-square distribution (df={df})')\n",
        "plt.axvline(lower_critical, color='red', linestyle='--', label=f'Lower critical value ({lower_critical:.2f})')\n",
        "plt.axvline(upper_critical, color='red', linestyle='--', label=f'Upper critical value ({upper_critical:.2f})')\n",
        "plt.axvline(chi_square_stat, color='blue', linestyle='-', label=f'Test statistic ({chi_square_stat:.2f})')\n",
        "\n",
        "plt.fill_between(x, y, where=(x < lower_critical) | (x > upper_critical),\n",
        "                color='red', alpha=0.2, label='Rejection region')\n",
        "\n",
        "plt.title('Chi-Square Test for Population Variance', fontsize=14)\n",
        "plt.xlabel('Chi-square statistic', fontsize=12)\n",
        "plt.ylabel('Probability density', fontsize=12)\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "iXDDdKAZOK3r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "25'''Write a Python script to perform a Z-test for comparing proportions between two datasets or groups'''\n",
        "\n",
        "import numpy as np\n",
        "from scipy import stats\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def ztest_proportions_two_samples(successes_a, sample_size_a, successes_b, sample_size_b):\n",
        "    \"\"\"\n",
        "    Perform a two-sample Z-test for proportions.\n",
        "\n",
        "    Parameters:\n",
        "    successes_a, successes_b - Number of successes in each sample\n",
        "    sample_size_a, sample_size_b - Size of each sample\n",
        "\n",
        "    Returns:\n",
        "    z_score - The computed Z-statistic\n",
        "    p_value - The two-tailed p-value\n",
        "    \"\"\"\n",
        "    # Calculate proportions\n",
        "    p_a = successes_a / sample_size_a\n",
        "    p_b = successes_b / sample_size_b\n",
        "    p_pooled = (successes_a + successes_b) / (sample_size_a + sample_size_b)\n",
        "\n",
        "    # Calculate standard error\n",
        "    se = np.sqrt(p_pooled * (1 - p_pooled) * (1/sample_size_a + 1/sample_size_b))\n",
        "\n",
        "    # Calculate Z-score\n",
        "    z_score = (p_a - p_b) / se\n",
        "\n",
        "    # Calculate two-tailed p-value\n",
        "    p_value = 2 * (1 - stats.norm.cdf(abs(z_score)))\n",
        "\n",
        "    return z_score, p_value\n",
        "\n",
        "# Example usage:\n",
        "# Group A: 120 successes out of 500 trials\n",
        "# Group B: 150 successes out of 500 trials\n",
        "successes_a = 120\n",
        "sample_size_a = 500\n",
        "successes_b = 150\n",
        "sample_size_b = 500\n",
        "\n",
        "# Perform the test\n",
        "z_score, p_value = ztest_proportions_two_samples(successes_a, sample_size_a, successes_b, sample_size_b)\n",
        "\n",
        "# Print results\n",
        "print(f\"Group A proportion: {successes_a/sample_size_a:.4f}\")\n",
        "print(f\"Group B proportion: {successes_b/sample_size_b:.4f}\")\n",
        "print(f\"\\nZ-test results:\")\n",
        "print(f\"Z-score: {z_score:.4f}\")\n",
        "print(f\"P-value: {p_value:.4f}\")\n",
        "\n",
        "# Interpretation\n",
        "alpha = 0.05\n",
        "print(\"\\nConclusion:\")\n",
        "if p_value < alpha:\n",
        "    print(f\"We reject the null hypothesis (p < {alpha}). There is significant evidence that the proportions are different.\")\n",
        "else:\n",
        "    print(f\"We fail to reject the null hypothesis (p ‚â• {alpha}). No significant difference in proportions detected.\")\n",
        "\n",
        "# Visualization\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.bar(['Group A', 'Group B'],\n",
        "        [successes_a/sample_size_a, successes_b/sample_size_b],\n",
        "        color=['blue', 'orange'])\n",
        "plt.errorbar(['Group A', 'Group B'],\n",
        "             [successes_a/sample_size_a, successes_b/sample_size_b],\n",
        "             yerr=[1.96*np.sqrt((successes_a/sample_size_a)*(1-successes_a/sample_size_a)/sample_size_a,\n",
        "                   1.96*np.sqrt((successes_b/sample_size_b)*(1-successes_b/sample_size_b)/sample_size_b)],\n",
        "             fmt='none', color='black', capsize=10)\n",
        "plt.title('Proportion Comparison Between Groups', fontsize=14)\n",
        "plt.xlabel('Groups', fontsize=12)\n",
        "plt.ylabel('Proportion', fontsize=12)\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.text(0.5, max(successes_a/sample_size_a, successes_b/sample_size_b)*0.9,\n",
        "         f'Z = {z_score:.2f}, p = {p_value:.4f}',\n",
        "         ha='center', va='center', fontsize=12)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "KhS7phbvOhb4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "26'''Implement an F-test for comparing the variances of two datasets, then interpret and visualize the results'''\n",
        "\n"
      ],
      "metadata": {
        "id": "9npak5jxO0KW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}